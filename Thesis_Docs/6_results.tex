%\include{packages}
%\begin{document}

\chapter{Results}\label{results}

\citep{AdamsH.H.Hieab2013RMfD}

\section{Reference Model Results}

Results from running Ghafoorian's model. Training time, and final sensitivity and average false-positives per slice.


Attempt1: training/testing in ratio 70:30. Here, only 7\% of data consists of positives. 41819 samples in total. Validation occurs on first 500 of the testing set. Training time: 02:04:48.
Training accuracy achieved 100\% before batch 100. Validation accuracy peaked at epoch 8, with an accuracy of 100\%. Though should be noted that the size of this validation set consists of only 500 samples. Testing the whole testing set (15544 samples) achieves an accuracy of 0.9938.

Attempt2: training/validation/testing in ratio 50:25:25. 1/3 of data was positives. 11539 samples in total. Training time: 00:23:11.
Training accuracy achieved 100\% before batch 50. Validation accuracy peaked at epoch 21, which achieved an accuracy of 0.984055. Applying this best validation model to testing data achieved an accuracy of 0.9833622. Lower accuracy could be the result of fewer data points for training - caused by having only a limited number of positives in the original dataset compared to the abundant negatives.

Attempt3: Use original 7\% ratio. 41819 samples, with training/validation/testing in ratio 50:25:25. Have to be careful not to introduce too many negatives as this could impact what the model attempts to predict. E.g. if there are only 1\% positives, then an accuracy of 99\% could be achieved just by labelling all the samples as negative. Training time: 01:58:23.
Training accuracy achieved 100\% before batch 100. Validation accuracy peaked at epoch 18, with an accuracy of 0.9979159, with the set containing 12955 samples. The testing set achieved an accuracy of 0.9972.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\include{bibliography}