%\include{packages}
%\begin{document}

\chapter{Introduction}\label{s-intro}

{\noindent} Cerebral Small Vessel Disease (\textsc{svd}) describes a set of abnormalities affecting small blood vessels in the deep grey and white matter of the brain. The changes are particularly prevalent amongst the elderly, with \textsc{svd} biomarkers appearing in over 90\% of \textsc{mri} for those aged 60--90 years \citep{deLeeuwF-E2001Pocw}. \textsc{svd} is the primary cause of a quarter of ischaemic (oxygen-starved) strokes \citep{WardlawJ.M.2013Nsfr} and is a major cause of dementia and cognitive decline \citep{NorrvingBo2008Linb}.

Imaging markers of \textsc{svd} include lacunes, enlarged perivascular spaces, white matter hyperintensities, microbleeds, recent small subcortical infarcts, and brain atrophy \citep{WardlawJ.M.2013Nsfr}. Current research investigates the role of  biomarkers in the advancement of \textsc{svd} as the extent to which the disease affects cognition, or which particular events are to blame, is not clear. Consequently, clear identification of biomarkers is needed to ensure valid diagnosis and further research.

The identification of \textsc{svd} biomarkers in \textsc{mri} (known as image \textit{rating}) is generally conducted by eye. The three-dimensional image constructed by an \textsc{mri} scan is made up of numerous two-dimensional \textit{slices}. Trained clinicians, with reference to the \textsc{strive} criterion \citep{WardlawJ.M.2013Nsfr}, examine each image slice for lesions and other features of interest. The locations and sizes of these features are logged manually and is therefore a very time consuming task. \cite{Heuvel2016} claim that the rating of a single brain scan takes approximately one hour. Additionally, neuroscientists have commented on the difficulty and reliability of these rating methods \citep{BenjaminJ.Philip2018LIbN, GhafoorianM.2017Dml3, Yokoyama2007}. \cite{WardlawJm2013Mosc} advise caution when establishing research conclusions as many of the features are difficult to differentiate. 

%This was especially the case for research coordinated prior to 2013, before the \textsc{strive} criterion was established \citep{WardlawJ.M.2013Nsfr}.
%
%Several attempts have been made to improve the reliability of visual rating, with moderate success \citep{AdamsH.H.Hieab2013RMfD, PotterGillian2015CPSV}. However intra-rater and inter-rater percentage agreements are still low for brain regions with a higher frequency of lacunes and perivascular spaces, such as the basal ganglia. In the trial by \cite{PotterGillian2015CPSV},  the intra-rater and inter-rater agreements for the basal ganglia were 0.54--0.68 and 0.65--0.77 respectively. This was considered an improvement, however the extent of the remaining inconsistencies means that caution must be taken when drawing conclusions.

Lacunes are of particular interest as the role of lacunes in \textsc{svd} and in the incidence of stroke is under review. For instance, \cite{BenjaminJ.Philip2018LIbN} argue that it is only lacunes, rather than perivascular spaces, that influence cognitive decline. They suspect that previous observed influence of perivascular spaces may have been the result of incorrect classification during the rating process.

Attempts at improving the accuracy, efficiency, and consistency of image rating has been undertaken through the use of automation. \cite{Yokoyama2007} determined candidate lacunes by considering the candidate's distance to central structures of the brain. False-positives were reduced by developing thresholds on the candidates' area, perimeter, and centre of gravity. The model had a lacune sensitivity of 90.1\%, specificity of 30.0\%, and had an average of 1.7 false-positives per image slice. \cite{Uchiyama20071554, Uchiyama2007b} used the method developed by \cite{Yokoyama2007} and further reduced false-positives by feeding twelve additional location and visual variables into two machine learning models: a support vector machine and a neural network. The resulting models had a sensitivity of 96.8\%, and had an average of 0.76 false-positives per slice. These models were revised by \citep{Uchiyama2015}, with false-positives reduced by matching candidate lacunes with image templates. The resulting model had a sensitivity of 96.8\% with 0.47 false-positives per slice. The sensitivities of these models are moderately high and demonstrate efficacy at identifying lacunes, however further improvements can be made to ensure that the models can run without clinician supervision.

Improvements in image classification have been made with the introduction of convolutional neural networks (\textsc{cnn}s). The AlexNet \textsc{cnn} model \citep{AlexNet2012} performed most accurately of all model entries on the ImageNet data set, which contains $1.5\times10^{7}$ images to be classified from $2.2\times10^5$ categories. A \textsc{cnn} was successfully applied to the \textsc{mri} context by \cite{DouQ.2016ADoC}, resulting in accurate detection of cerebral microbleeds.

A successful \textsc{cnn} model for lacune detection was first developed by \cite{GhafoorianM.2017Dml3}. This model involved a two-dimensional \textsc{cnn} for candidate lacune detection, followed by three parallel three-dimensional \textsc{cnn}s connected with seven additional location-based variables, to reduce the number of false-positive classifications. This model exhibited a sensitivity of 97.4\% and exhibited an average of 0.13 false-positives per slice. Although the model demonstrates highly accurate performance, it relies on the inclusion of location-based variables. Some of these variables include distances between the candidate points and particular structures of the brain. However, the precise locations and sizes of these brain structures are not constant between scans. These location-based variables must be estimated using existing algorithms or, in the case that a clinician does not have access to these algorithms, measured manually. 

In this thesis, we adapt the \textsc{cnn} developed by \cite{GhafoorianM.2017Dml3} to the scenario in which the location-based variables are unavailable. In particular, we make three major adjustments. The first is the \textit{removal of the location-based variables} presumed to be inaccessible. The second adjustment is the \textit{extraction of brain matter} to remove visual identifiers such as the skull and eyes. The third adjustment is the \textit{removal of early dimension reduction} to ensure that adequate pixel information is being passed to the first layer of the \textsc{cnn}.

The resulting model exhibits a testing sensitivity of 99.9\% and specificity of 99.8\%. This improved sensitivity indicates that the model is as sensitive to lacunes as a trained clinician. Improving model specificity minimises the time spent checking the model results. A model with a very large number of false-positives may take just as long to correct as the rating of a whole scan. Improvement in specificity may be achieved by applying a three-dimensional \textsc{cnn} to improve image context, or by the inclusion of simple location-based variables, such as the $x$, $y$, and $z$-coordinates. It should be noted that these methods require additional data preprocessing before use in a data pipeline.

%It should be noted that the quality of the responses is limited by the reliability of lacune classification amongst clinicians. Hence further improvement of sensitivity rates 

We now outline the structure of the remainder of this thesis.

In Chapter 2, we introduce terminology surrounding \textsc{mri} and the structure of the brain. We formally define the biomarkers involved in \textsc{svd} and how they are identified. We discuss current image rating methods and the need for automated image rating algorithms.

In Chapter 3, we introduce the structure of neural networks and discuss the choice of activation and cost functions. We show that the minimum of the cost function can be estimated using the Gradient Descent algorithm, and finally discuss methods that mitigate overfitting of the data.

In Chapter 4, we introduce convolutional neural networks for image classification tasks. We outline techniques that improve training efficiency given a large number of variables to be estimated.

In Chapter 5, we discuss the efficacy of existing models, outline the structure of the lacune identification model built by \cite{GhafoorianM.2017Dml3}, and outline the proposed changes to the model.

In Chapter 6, we describe the methods of data collection and the preprocessing applied to the collected scans. We also describe the methods of data sampling before model implementation.

In Chapter 7, we present the results of two \textsc{cnn}s. We test the significance of a greater proportion of negative samples during training, and determine the final testing sensitivity and specificity rates. We discuss the final behaviour of the model, including the characteristics of samples that incur model error.

In Chapter 8, we discuss existing sample correlations between the training, validation, and testing data sets. We outline the results of the revised models, discuss updated model improvements, and review the existing model false-positive rate.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\include{bibliography}
%\end{document}